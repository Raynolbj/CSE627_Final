# ğŸš— Road Skeletonization with U-Net

This project implements a deep learning-based approach to skeletonize road networks from noisy, thick raster images using OpenStreetMap (OSM) data. It includes data generation, training with a U-Net model, evaluation (both visual and quantitative), and an ablation study framework.

---

## ğŸ“ Directory Structure

```
CSE627_FINAL/
â”œâ”€â”€ cache/                    # Cached OSM data
â”œâ”€â”€ checkpoints/              # Saved model checkpoints
â”œâ”€â”€ data/                     # Image and target PNGs
â”‚   â””â”€â”€ thinning/
â”‚       â”œâ”€â”€ inputs/           # Noisy thick road input images
â”‚       â””â”€â”€ targets/          # Ground truth 1px skeletons
â”œâ”€â”€ models/                   # UNet and node metrics implementation
â”œâ”€â”€ predictions/              # Sample outputs during training
â”œâ”€â”€ results/                  # Visuals + metrics from evaluations and ablation
â”œâ”€â”€ scripts/                  # All Python scripts
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ train_eval_ablation.py
â”‚   â”œâ”€â”€ evaluate_sample.py
â”‚   â””â”€â”€ evaluate_debug_valence.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§© Setup Instructions

1. **Clone the repository**
2. **Install dependencies**:

```bash
pip install -r requirements.txt
```

3. **Generate dataset**:

Run the data generation script (inside `thinning_data/trace/models/thinning/`) to populate `data/thinning/inputs` and `data/thinning/targets`.

```bash
python make_data.py
```

4. **Train the model**:

To train a U-Net model on the generated dataset:
```bash
python scripts/train.py
```

This saves sample predictions and checkpoints under `/checkpoints` and `/predictions`.

5. **Run evaluation on trained model**:
```bash
python scripts/evaluate_sample.py
```

6. **Run full ablation study (3 configs)**:
```bash
python scripts/train_eval_ablation.py
```

This will train 3 variants of U-Net (different loss/learning rate), output:
- 3 qualitative prediction PNGs per run
- Loss, MSE, and valence-based node metrics for each sample

---

## ğŸ“Š Output Summary

Results are saved to `results/<config_name>_<timestamp>/` including:
- `qualitative_*.png`: input, target, prediction comparison
- `sample_X/loss.txt`
- `sample_X/mse.txt`
- `sample_X/node_metrics.csv`

---

## ğŸ“Œ Notes

- Predictions are binarized and cleaned before skeletonization.
- Evaluation includes node-level precision/recall for 1â€“4 valent nodes.
- The pipeline is modular, so you can rerun evaluation without retraining.

---


