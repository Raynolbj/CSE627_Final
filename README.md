# ğŸš— Road Skeletonization with U-Net

This project implements a deep learning-based approach to skeletonize road networks from noisy, thick raster images using OpenStreetMap (OSM) data. It includes data generation, training with a U-Net model, evaluation (both visual and quantitative), and an ablation study framework.

---

## ğŸ“ Directory Structure

```
CSE627_FINAL/
â”œâ”€â”€ cache/                        # Cached or temporary data
â”œâ”€â”€ checkpoints/                  # Trained model checkpoint files (.pt)
â”œâ”€â”€ data/                         # Original image data (optional, legacy)
â”œâ”€â”€ thinning_data/                # Main dataset location
â”‚   â”œâ”€â”€ inputs/                   # Thick road input images (PNG)
â”‚   â””â”€â”€ targets/                  # Ground truth 1px-wide skeletons
â”œâ”€â”€ models/                       # UNet architecture and node metric utils
â”‚   â”œâ”€â”€ unet.py
â”‚   â””â”€â”€ node_metrics.py
â”œâ”€â”€ predictions/                  # (Optional) saved outputs from test runs
â”œâ”€â”€ results/                      # All evaluation outputs (images + CSVs)
â”‚   â”œâ”€â”€ baseline/                     # From baseline config
â”‚   â”œâ”€â”€ alt_loss/                     # From alt_loss config
â”‚   â”œâ”€â”€ low_lr/                       # From low_lr config
â”‚   â””â”€â”€ sample/                       # From manual evaluation scripts
â”œâ”€â”€ scripts/                      # All training/evaluation scripts
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ train_eval_ablation.py         # Runs all configs & saves checkpoints
â”‚   â”œâ”€â”€ evaluate_sample.py             # Manual inspection of a single prediction
â”‚   â”œâ”€â”€ evaluate_debug_valence.py      # Visual/debug view of valence structures
â”‚   â””â”€â”€ compare_all_outputs_with_target.py  # Side-by-side visual + metrics
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§© Setup Instructions

1. **Clone the repository**
2. **Install dependencies**:

```bash
pip install -r requirements.txt
```

3. **Generate dataset**:

Run the data generation script (inside `thinning_data/trace/models/thinning/`) to populate `data/thinning/inputs` and `data/thinning/targets`.

```bash
python make_data.py
```

4. **Train the model**:

To train a U-Net model on the generated dataset:
```bash
python scripts/train.py
```

This saves sample predictions and checkpoints under `/checkpoints` and `/predictions`.

5. **Run evaluation on trained model**:
```bash
python scripts/evaluate_sample.py
```

6. **Run full ablation study (3 configs)**:
```bash
python scripts/train_eval_ablation.py
```

This will train 3 variants of U-Net (different loss/learning rate), output:
- 3 qualitative prediction PNGs per run
- Loss, MSE, and valence-based node metrics for each sample

---

## ğŸ“Š Output Summary

Results are saved to `results/<config_name>_<timestamp>/` including:
- `qualitative_*.png`: input, target, prediction comparison
- `sample_X/loss.txt`
- `sample_X/mse.txt`
- `sample_X/node_metrics.csv`

---

## ğŸ“Œ Notes

- Predictions are binarized and cleaned before skeletonization.
- Evaluation includes node-level precision/recall for 1â€“4 valent nodes.
- The pipeline is modular, so you can rerun evaluation without retraining.

---


